"use strict";
var __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {
    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }
    return new (P || (P = Promise))(function (resolve, reject) {
        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }
        function rejected(value) { try { step(generator["throw"](value)); } catch (e) { reject(e); } }
        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }
        step((generator = generator.apply(thisArg, _arguments || [])).next());
    });
};
var __generator = (this && this.__generator) || function (thisArg, body) {
    var _ = { label: 0, sent: function() { if (t[0] & 1) throw t[1]; return t[1]; }, trys: [], ops: [] }, f, y, t, g;
    return g = { next: verb(0), "throw": verb(1), "return": verb(2) }, typeof Symbol === "function" && (g[Symbol.iterator] = function() { return this; }), g;
    function verb(n) { return function (v) { return step([n, v]); }; }
    function step(op) {
        if (f) throw new TypeError("Generator is already executing.");
        while (g && (g = 0, op[0] && (_ = 0)), _) try {
            if (f = 1, y && (t = op[0] & 2 ? y["return"] : op[0] ? y["throw"] || ((t = y["return"]) && t.call(y), 0) : y.next) && !(t = t.call(y, op[1])).done) return t;
            if (y = 0, t) op = [op[0] & 2, t.value];
            switch (op[0]) {
                case 0: case 1: t = op; break;
                case 4: _.label++; return { value: op[1], done: false };
                case 5: _.label++; y = op[1]; op = [0]; continue;
                case 7: op = _.ops.pop(); _.trys.pop(); continue;
                default:
                    if (!(t = _.trys, t = t.length > 0 && t[t.length - 1]) && (op[0] === 6 || op[0] === 2)) { _ = 0; continue; }
                    if (op[0] === 3 && (!t || (op[1] > t[0] && op[1] < t[3]))) { _.label = op[1]; break; }
                    if (op[0] === 6 && _.label < t[1]) { _.label = t[1]; t = op; break; }
                    if (t && _.label < t[2]) { _.label = t[2]; _.ops.push(op); break; }
                    if (t[2]) _.ops.pop();
                    _.trys.pop(); continue;
            }
            op = body.call(thisArg, _);
        } catch (e) { op = [6, e]; y = 0; } finally { f = t = 0; }
        if (op[0] & 5) throw op[1]; return { value: op[0] ? op[1] : void 0, done: true };
    }
};
var __importDefault = (this && this.__importDefault) || function (mod) {
    return (mod && mod.__esModule) ? mod : { "default": mod };
};
var llmprompts_1 = __importDefault(require("./llmprompts"));
var utils_1 = __importDefault(require("./utils"));
var AIDapter = (function () {
    function AIDapter(llmConfig) {
        this.utils = new utils_1.default();
        this.llm = {
            "provider": "OpenAI",
            "model_name": "gpt-3.5-turbo-16k",
            "endpoint": "https://api.openai.com/v1/chat/completions",
            "authentication": {
                "api_key": "",
                "org_id": ""
            }
        };
        this.llm.provider = llmConfig.provider || this.llm.provider;
        this.llm.model_name = llmConfig.model_name || this.llm.model_name;
        this.llm.endpoint = llmConfig.endpoint || this.llm.endpoint;
        this.llm.authentication.api_key = llmConfig.authentication.api_key || this.llm.authentication.api_key;
        this.llm.authentication.org_id = llmConfig.authentication.org_id || this.llm.authentication.org_id;
    }
    ;
    AIDapter.prototype.getRealtimeSources = function (input, apiRepository) {
        var _this = this;
        return new Promise(function (resolve, reject) { return __awaiter(_this, void 0, void 0, function () {
            var llmPrompts, prompt, resp, _a, llmResponse, payload;
            return __generator(this, function (_b) {
                switch (_b.label) {
                    case 0:
                        llmPrompts = new llmprompts_1.default();
                        prompt = llmPrompts.forRealtimeSources(input, apiRepository);
                        resp = {};
                        _a = this.llm.provider;
                        switch (_a) {
                            case "OpenAI": return [3, 1];
                        }
                        return [3, 3];
                    case 1: return [4, this.utils.callOpenAI(this.llm, prompt)];
                    case 2:
                        resp = _b.sent();
                        return [3, 4];
                    case 3: return [3, 4];
                    case 4:
                        ;
                        llmResponse = resp.data.choices[0].message.content;
                        payload = JSON.parse(llmResponse.substring(llmResponse.indexOf('{'), llmResponse.lastIndexOf('}') + 1));
                        if (!payload['api_endpoints'])
                            payload['api_endpoints'] = [];
                        payload['tokens'] = resp.data.usage;
                        this.utils.log("I", payload.api_endpoints.length + " APIs identified");
                        resolve(payload);
                        return [2];
                }
            });
        }); });
    };
    ;
    AIDapter.prototype.getDataFromRealtimeSource = function (input, apiRepository, dataConfig) {
        var _this = this;
        return new Promise(function (resolve, reject) {
            var inprogress = true;
            var addContext = [];
            var entities = [];
            var question = [];
            if (dataConfig === null || dataConfig === void 0 ? void 0 : dataConfig.additional_context) {
                var maxContext = ((dataConfig === null || dataConfig === void 0 ? void 0 : dataConfig.max_contexts) && (dataConfig === null || dataConfig === void 0 ? void 0 : dataConfig.max_contexts) > 0) ? ((dataConfig === null || dataConfig === void 0 ? void 0 : dataConfig.max_contexts) > 2 ? 2 : dataConfig === null || dataConfig === void 0 ? void 0 : dataConfig.max_contexts) : 2;
                dataConfig === null || dataConfig === void 0 ? void 0 : dataConfig.additional_context.splice(0, (dataConfig === null || dataConfig === void 0 ? void 0 : dataConfig.additional_context.length) - maxContext);
                dataConfig === null || dataConfig === void 0 ? void 0 : dataConfig.additional_context.forEach(function (context) {
                    if (Object.keys(context).length > 0) {
                        if (context.original_question)
                            question.push(context.original_question);
                        if (context.response_summary)
                            addContext.push(context.response_summary);
                        if (context.entities)
                            entities.push(context.entities);
                    }
                });
            }
            question.push(input);
            var updatedInput = (addContext.length ? "\nAdditional context:\n" + addContext.join(". ") : "") + "\n" + JSON.stringify(entities);
            updatedInput += "\nQuestion:\n" + question.join(". ");
            _this.utils.log("I", "Input for obtaining realtime sources:\n---" + updatedInput + "\n---\n");
            _this.getRealtimeSources(updatedInput, apiRepository)
                .then(function (payload) {
                var apiResults = [];
                payload.api_endpoints.forEach(function (api_endpoint, i) {
                    if (api_endpoint['status']) {
                        if (api_endpoint.status == "OK") {
                            _this.utils.callAPI(api_endpoint.api.method, api_endpoint.api.url, api_endpoint.api.headers, api_endpoint.api.data || false)
                                .then(function (resp) {
                                _this.utils.log("I", "[" + resp.status + "] " + api_endpoint.api.url);
                                var maxRecords = ((dataConfig === null || dataConfig === void 0 ? void 0 : dataConfig.max_records) && (dataConfig === null || dataConfig === void 0 ? void 0 : dataConfig.max_records) > 0) ? ((dataConfig === null || dataConfig === void 0 ? void 0 : dataConfig.max_records) > 10 ? 10 : dataConfig === null || dataConfig === void 0 ? void 0 : dataConfig.max_records) : 10;
                                var response = resp.data;
                                Object.keys(response).forEach(function (key) {
                                    if (Array.isArray(response[key])) {
                                        response[key].splice(maxRecords);
                                    }
                                });
                                apiResults.push(response);
                                if (apiResults.length == payload.api_endpoints.length)
                                    inprogress = false;
                            }).catch(function (err) {
                                _this.utils.log("E", api_endpoint.api.url, err);
                                reject({
                                    "api_results": err,
                                    "tokens": payload.tokens
                                });
                            });
                        }
                        else {
                            _this.utils.log("W", api_endpoint.api.url + " has missing placeholder values");
                            var placeholdersUndetermined_1 = [];
                            if (api_endpoint['placeholders']) {
                                api_endpoint.placeholders.forEach(function (placeholder) {
                                    if (placeholder['placeholder']) {
                                        if (!placeholder.determined)
                                            placeholdersUndetermined_1.push(placeholder.placeholder);
                                    }
                                });
                                _this.utils.log("W", placeholdersUndetermined_1.length + " placeholders undetermined", placeholdersUndetermined_1.join(","));
                                if (placeholdersUndetermined_1.length) {
                                    apiResults.push({ "missing_placeholder_values": placeholdersUndetermined_1.join(",") });
                                    if (apiResults.length == payload.api_endpoints.length)
                                        inprogress = false;
                                }
                            }
                            else {
                                _this.utils.log("W", api_endpoint.api.url + " has no placeholders");
                                apiResults.push('-');
                                if (apiResults.length == payload.api_endpoints.length)
                                    inprogress = false;
                            }
                        }
                    }
                    else {
                        _this.utils.log("W", api_endpoint.api.url + " has no status");
                        apiResults.push('-');
                        if (apiResults.length == payload.api_endpoints.length)
                            inprogress = false;
                    }
                });
                var timeout = (12 * payload.api_endpoints.length);
                var intvl = setInterval(function () {
                    if (!inprogress || timeout <= 0) {
                        clearInterval(intvl);
                        resolve({
                            "api_results": apiResults,
                            "tokens": payload.tokens
                        });
                    }
                    else
                        timeout--;
                }, 500);
            }).catch(function (err) {
                _this.utils.log("E", "Getting realtime sources failed", err);
                reject({
                    "api_results": err,
                    "tokens": {
                        "prompt_tokens": 0,
                        "completion_tokens": 0,
                        "total_tokens": 0
                    }
                });
            });
        });
    };
    ;
    AIDapter.prototype.getLLMResponseFromRealtimeSources = function (input, apiRepository, options) {
        var _this = this;
        return new Promise(function (resolve, reject) {
            _this.getDataFromRealtimeSource(input, apiRepository, options === null || options === void 0 ? void 0 : options.dataConfig)
                .then(function (realtimeData) { return __awaiter(_this, void 0, void 0, function () {
                var llmPrompts, prompt, resp, _a, payload, possibleResponses, possibleResponses;
                return __generator(this, function (_b) {
                    switch (_b.label) {
                        case 0:
                            this.utils.log("I", "Got " + realtimeData.api_results.length + " results from API calls");
                            if (!realtimeData.api_results.length) return [3, 5];
                            llmPrompts = new llmprompts_1.default();
                            prompt = llmPrompts.forResponseWithData(input, realtimeData.api_results, options === null || options === void 0 ? void 0 : options.agentConfig);
                            resp = {};
                            _a = this.llm.provider;
                            switch (_a) {
                                case "OpenAI": return [3, 1];
                            }
                            return [3, 3];
                        case 1: return [4, this.utils.callOpenAI(this.llm, prompt)];
                        case 2:
                            resp = _b.sent();
                            return [3, 4];
                        case 3: return [3, 4];
                        case 4:
                            ;
                            this.utils.log("I", "Generating response...");
                            if (resp.status == 200) {
                                this.utils.log("I", "Response OK");
                                payload = (resp.data.choices[0].message.content.indexOf('{') >= 0 && resp.data.choices[0].message.content.lastIndexOf('}') > 0) ?
                                    JSON.parse(resp.data.choices[0].message.content.substring(resp.data.choices[0].message.content.indexOf('{'), resp.data.choices[0].message.content.lastIndexOf('}') + 1))
                                    :
                                        {
                                            "response": resp.data.choices[0].message.content,
                                            "status": "INCOMPLETE",
                                            "additional_context": {
                                                "conversation": {
                                                    "original_question": input,
                                                    "response_summary": resp.data.choices[0].message.content.substring(0, 25)
                                                },
                                                "additional_context": {},
                                                "entities": {}
                                            },
                                        };
                                resolve({
                                    "ai_response": payload.response,
                                    "ai_status": payload.status,
                                    "ai_context": payload.additional_context,
                                    "tokens": {
                                        "api_identification": realtimeData.tokens,
                                        "llm_response": resp.data.usage,
                                        "prompt_tokens": realtimeData.tokens['prompt_tokens'] + resp.data.usage['prompt_tokens'],
                                        "completion_tokens": realtimeData.tokens['completion_tokens'] + resp.data.usage['completion_tokens'],
                                        "total_tokens": realtimeData.tokens['total_tokens'] + resp.data.usage['total_tokens']
                                    }
                                });
                            }
                            else {
                                this.utils.log("W", "Response NOT OK");
                                possibleResponses = [
                                    "Sorry! Looks like we failed to receive a response back. Do you mind trying again?",
                                    "Oh! Sorry, but we did not receive a proper response for you. Would you like to try again?"
                                ];
                                resolve({
                                    "ai_response": possibleResponses[Math.floor(Math.random() * possibleResponses.length)],
                                    "ai_status": "INCOMPLETE",
                                    "ai_context": {
                                        "conversation": {
                                            "original_question": input,
                                            "response_summary": possibleResponses[Math.floor(Math.random() * possibleResponses.length)]
                                        },
                                        "additional_context": {},
                                        "entities": {}
                                    },
                                    "tokens": {
                                        "api_identification": realtimeData.tokens,
                                        "llm_response": resp.data.usage,
                                        "prompt_tokens": realtimeData.tokens['prompt_tokens'] + resp.data.usage['prompt_tokens'],
                                        "completion_tokens": realtimeData.tokens['completion_tokens'] + resp.data.usage['completion_tokens'],
                                        "total_tokens": realtimeData.tokens['total_tokens'] + resp.data.usage['total_tokens']
                                    }
                                });
                            }
                            return [3, 6];
                        case 5:
                            this.utils.log("W", "No APIs were identified");
                            possibleResponses = [
                                "Sorry! We could not find a realtime source from where this information could be obtained. Would you mind rephrasing your question and trying again?",
                                "Oh! Unfortunately we did not find a realtime source that can help answer that question. Could you please rephrase and ask again?"
                            ];
                            resolve({
                                "ai_response": possibleResponses[Math.floor(Math.random() * possibleResponses.length)],
                                "ai_status": "INCOMPLETE",
                                "ai_context": {
                                    "conversation": {
                                        "original_question": input,
                                        "response_summary": possibleResponses[Math.floor(Math.random() * possibleResponses.length)]
                                    },
                                    "additional_context": {},
                                    "entities": {}
                                },
                                "tokens": {
                                    "api_identification": realtimeData.tokens,
                                    "llm_response": {
                                        "prompt_tokens": 0,
                                        "completion_tokens": 0,
                                        "total_tokens": 0
                                    },
                                    "prompt_tokens": realtimeData.tokens['prompt_tokens'],
                                    "completion_tokens": realtimeData.tokens['completion_tokens'],
                                    "total_tokens": realtimeData.tokens['total_tokens']
                                }
                            });
                            _b.label = 6;
                        case 6: return [2];
                    }
                });
            }); }).catch(function (err) {
                _this.utils.log("E", "Getting realtime data failed", err);
                reject(err);
            });
        });
    };
    ;
    return AIDapter;
}());
;
module.exports = AIDapter;
